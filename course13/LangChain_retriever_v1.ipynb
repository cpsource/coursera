{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2531ca07-a199-45dd-b7b3-b90375d10330"
      },
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5fc16e-f9e3-44e6-8214-afee3d524ffd"
      },
      "source": [
        "# **Develop a Retriever to Fetch Document Segments Based on Queries**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8202a04f-ea75-4b68-82e1-d94e96b14f42"
      },
      "source": [
        "Estimated time needed: **40** minutes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58036635-e5c7-4b27-9d84-370b67df1361"
      },
      "source": [
        "## Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "781c328d-ab46-4574-89a2-bb93f4e88d77"
      },
      "source": [
        "Imagine you are working on a project that involves processing a large collection of text documents, such as research papers, legal documents, or customer service logs. Your task is to develop a system that can quickly retrieve the most relevant segments of text based on a user's query. Traditional keyword-based search methods might not be sufficient, as they often fail to capture the nuanced meanings and contexts within the documents. To address this challenge, you can use different types of retrievers based on LangChain.\n",
        "\n",
        "Using retrievers is crucial for several reasons:\n",
        "\n",
        "- Efficiency: Retrievers enable fast and efficient retrieval of relevant information from large datasets, saving time and computational resources.\n",
        "- Accuracy: By leveraging advanced retrieval techniques, these tools can provide more accurate and contextually relevant results compared to traditional search methods.\n",
        "- Versatility: Different retrievers can be tailored to specific use cases, making them adaptable to various types of text data and query requirements.\n",
        "- Context awareness: Some retrievers, like the Parent Document Retriever, can consider the broader context of the document, enhancing the relevance of the retrieved segments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "340431c5-aa35-467d-b0ef-ff0a0ecde848"
      },
      "source": [
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/EUODrOFxvSSNL935zpwh9A/retriever.png\" width=\"50%\" alt=\"retriever\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95f0c2ba-a065-4ee0-9850-bfe782f4da37"
      },
      "source": [
        "In this lab, you will learn how to use various retrievers to efficiently extract relevant document segments from text using LangChain.\n",
        "You will learn about four types of retrievers: `Vector Store-backed Retriever`, `Multi-Query Retriever`, `Self-Querying Retriever`, and `Parent Document Retriever`. You will also learn the differences between these retrievers and understand the appropriate situations in which to use each one. By the end of this lab, you will be equipped with the skills to implement and utilize these retrievers in your projects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d14b4106-caa1-43e1-86eb-db6fcbdaade9"
      },
      "source": [
        "## __Table of Contents__\n",
        "\n",
        "<ol>\n",
        "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
        "    <li>\n",
        "        <a href=\"#Setup\">Setup</a>\n",
        "        <ol>\n",
        "            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n",
        "            <li><a href=\"#Defining-helper-functions\">Defining helper functions</a>\n",
        "                <ol>\n",
        "                    <li><a href=\"#Build-LLM\">Build LLM</a></li>\n",
        "                    <li><a href=\"#Text-splitter\">Text splitter</a></li>\n",
        "                    <li><a href=\"#Embedding-model\">Embedding model</a></li>\n",
        "                </ol>\n",
        "            </li>\n",
        "        </ol>\n",
        "    </li>\n",
        "    <li>\n",
        "        <a href=\"#Retrievers\">Retrievers</a>\n",
        "        <ol>\n",
        "            <li><a href=\"#Vector-Store-Backed-Retriever\">Vector Store-Backed Retriever</a></li>\n",
        "            <li><a href=\"#Multi-Query-Retriever\">Multi-Query Retriever</a></li>\n",
        "            <li><a href=\"#Self-Querying-Retriever\">Self-Querying Retriever</a></li>\n",
        "            <li><a href=\"#Parent-Document-Retriever\">Parent Document Retriever</a></li>\n",
        "        </ol>\n",
        "\n",
        "   \n",
        "            \n",
        "<li><a href=\"#Exercises\">Exercises</a>\n",
        "<ol>\n",
        "<li><a href=\"#Retrieve-top-2-results-using-vector-store-backed-retriever\">Retrieve top 2 results using vector store-backed retriever</a></li>\n",
        "<li><a href=\"#Self-Querying-Retriever-for-a-query\">Self querying retriever for a query</a></li>\n",
        "</ol>\n",
        "</li>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b49b4d7-2387-4c27-b27a-4d309104c122"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "After completing this lab, you will be able to:\n",
        "\n",
        "- Use various types of retrievers to efficiently extract relevant document segments from text, leveraging LangChain's capabilities.\n",
        "- Apply the Vector Store-backed Retriever to solve problems involving semantic similarity and relevance in large text datasets.\n",
        "- Utilize the Multi-Query Retriever to address situations where multiple query variations are needed to capture comprehensive results.\n",
        "- Implement the Self-Querying Retriever to automatically generate and refine queries, enhancing the accuracy of information retrieval.\n",
        "- Employ the Parent Document Retriever to maintain context and relevance by considering the broader context of the parent document.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fb6c235-52d7-4f08-a24d-7103e00b6cdf"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ea96fe-a370-4dfa-a736-bedd1ad46383"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d9f3ef1-9af4-4581-a343-f50b0ab073c2"
      },
      "source": [
        "For this lab, you will use the following libraries:\n",
        "\n",
        "*   [`ibm-watson-ai`](https://ibm.github.io/watsonx-ai-python-sdk/index.html) for using LLMs from IBM's watsonx.ai.\n",
        "*   [`langchain`, `langchain-ibm`, `langchain-community`](https://www.langchain.com/) for using relevant features from LangChain.\n",
        "*   [`pypdf`](https://pypi.org/project/pypdf/)is an open-source pure Python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files.\n",
        "*   [`chromadb`](https://www.trychroma.com/) is an open-source vector database used to store embeddings.\n",
        "*   [`lark`](https://pypi.org/project/lark/) is a general-purpose parsing library for Python. It is necessary for a Self-Querying Retriever.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7a63877-63f9-4e69-b0bf-8f08a8a90bf7"
      },
      "source": [
        "### Installing required libraries\n",
        "\n",
        "The following required libraries are __not__ preinstalled in the Skills Network Labs environment. __You must run the following cell__ to install them:\n",
        "\n",
        "**Note:** The version is being pinned here to specify the version. It's recommended that you do this as well. Even if the library is updated in the future, the installed library could still support this lab work.\n",
        "\n",
        "This might take approximately 1-2 minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38a80fdb-2853-48cd-910d-e7c6f56a7274"
      },
      "outputs": [],
      "source": [
        "# Please restart the kernel and run all cells after executing this cell.\n",
        "!pip install --user \"ibm-watsonx-ai==1.1.2\" | tail -n 1\n",
        "!pip install --user \"langchain==0.2.1\" | tail -n 1\n",
        "!pip install --user \"langchain-ibm==0.1.11\" | tail -n 1\n",
        "!pip install --user \"langchain-community==0.2.1\" | tail -n 1\n",
        "!pip install --user \"chromadb==0.4.24\" | tail -n 1\n",
        "!pip install --user \"pypdf==4.3.1\" | tail -n 1\n",
        "!pip install --user \"lark==1.1.9\" | tail -n 1"
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WWhfqnP8mICD",
        "outputId": "7906ff7e-968e-4066-9be3-6055252ee7bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: aiohttp==3.12.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (3.12.13)\n",
            "Requirement already satisfied: aiosignal==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (1.3.2)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: anyio==4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.9.0)\n",
            "Requirement already satisfied: attrs==25.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (25.3.0)\n",
            "Requirement already satisfied: backoff==2.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (2.2.1)\n",
            "Requirement already satisfied: bcrypt==4.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (4.3.0)\n",
            "Requirement already satisfied: build==1.2.2.post1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (1.2.2.post1)\n",
            "Requirement already satisfied: cachetools==5.5.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (5.5.2)\n",
            "Requirement already satisfied: certifi==2025.6.15 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer==3.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 39)) (3.4.2)\n",
            "Requirement already satisfied: chromadb==1.0.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 41)) (1.0.13)\n",
            "Requirement already satisfied: click==8.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (8.2.1)\n",
            "Requirement already satisfied: coloredlogs==15.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 47)) (15.0.1)\n",
            "Requirement already satisfied: dataclasses-json==0.6.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 49)) (0.6.7)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (1.9.0)\n",
            "Requirement already satisfied: durationpy==0.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 53)) (0.10)\n",
            "Requirement already satisfied: filelock==3.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 55)) (3.18.0)\n",
            "Requirement already satisfied: flatbuffers==25.2.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 57)) (25.2.10)\n",
            "Requirement already satisfied: frozenlist==1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 59)) (1.7.0)\n",
            "Collecting fsspec==2025.3.2 (from -r requirements.txt (line 63))\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting google-auth==2.38.0 (from -r requirements.txt (line 67))\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos==1.70.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 71)) (1.70.0)\n",
            "Requirement already satisfied: greenlet==3.2.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 73)) (3.2.3)\n",
            "Requirement already satisfied: grpcio==1.73.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 75)) (1.73.0)\n",
            "Requirement already satisfied: h11==0.16.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 79)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet==1.1.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 83)) (1.1.5)\n",
            "Requirement already satisfied: httpcore==1.0.9 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 85)) (1.0.9)\n",
            "Requirement already satisfied: httptools==0.6.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 87)) (0.6.4)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 89)) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 94)) (0.4.0)\n",
            "Requirement already satisfied: huggingface-hub==0.33.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 96)) (0.33.0)\n",
            "Requirement already satisfied: humanfriendly==10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 98)) (10.0)\n",
            "Collecting ibm-cos-sdk==2.13.5 (from -r requirements.txt (line 100))\n",
            "  Downloading ibm-cos-sdk-2.13.5.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cos-sdk-core==2.13.5 (from -r requirements.txt (line 102))\n",
            "  Downloading ibm-cos-sdk-core-2.13.5.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cos-sdk-s3transfer==2.13.5 (from -r requirements.txt (line 106))\n",
            "  Downloading ibm-cos-sdk-s3transfer-2.13.5.tar.gz (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ibm-watsonx-ai==1.3.26 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 108)) (1.3.26)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 112)) (3.10)\n",
            "Requirement already satisfied: importlib-metadata==8.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 118)) (8.7.0)\n",
            "Requirement already satisfied: importlib-resources==6.5.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 120)) (6.5.2)\n",
            "Requirement already satisfied: jmespath==1.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 122)) (1.0.1)\n",
            "Requirement already satisfied: jsonpatch==1.33 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 126)) (1.33)\n",
            "Requirement already satisfied: jsonpointer==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 128)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema==4.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 130)) (4.24.0)\n",
            "Requirement already satisfied: jsonschema-specifications==2025.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 132)) (2025.4.1)\n",
            "Requirement already satisfied: kubernetes==33.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 134)) (33.1.0)\n",
            "Requirement already satisfied: langchain==0.3.26 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 136)) (0.3.26)\n",
            "Requirement already satisfied: langchain-community==0.3.26 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 140)) (0.3.26)\n",
            "Requirement already satisfied: langchain-core==0.3.66 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 142)) (0.3.66)\n",
            "Requirement already satisfied: langchain-ibm==0.3.12 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 148)) (0.3.12)\n",
            "Requirement already satisfied: langchain-text-splitters==0.3.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 150)) (0.3.8)\n",
            "Requirement already satisfied: langsmith==0.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 152)) (0.4.1)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 157)) (1.2.2)\n",
            "Requirement already satisfied: lomond==0.3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 159)) (0.3.3)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 161)) (3.0.0)\n",
            "Requirement already satisfied: marshmallow==3.26.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 163)) (3.26.1)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 165)) (0.1.2)\n",
            "Requirement already satisfied: mmh3==5.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 167)) (5.1.0)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 169)) (1.3.0)\n",
            "Requirement already satisfied: multidict==6.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 171)) (6.5.0)\n",
            "Requirement already satisfied: mypy-extensions==1.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 175)) (1.1.0)\n",
            "Collecting numpy==2.0.2 (from -r requirements.txt (line 177))\n",
            "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib==3.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 184)) (3.3.1)\n",
            "Requirement already satisfied: onnxruntime==1.22.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 188)) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api==1.34.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 190)) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 196)) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.34.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 198)) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.34.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 200)) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-sdk==1.34.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 204)) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 208)) (0.55b1)\n",
            "Requirement already satisfied: orjson==3.10.18 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 210)) (3.10.18)\n",
            "Requirement already satisfied: overrides==7.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 214)) (7.7.0)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 216)) (24.2)\n",
            "Collecting pandas==2.2.2 (from -r requirements.txt (line 225))\n",
            "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: posthog==5.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 229)) (5.4.0)\n",
            "Requirement already satisfied: propcache==0.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 231)) (0.3.2)\n",
            "Requirement already satisfied: protobuf==5.29.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 235)) (5.29.5)\n",
            "Requirement already satisfied: pyasn1==0.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 240)) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules==0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 244)) (0.4.2)\n",
            "Requirement already satisfied: pybase64==1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 246)) (1.4.1)\n",
            "Requirement already satisfied: pydantic==2.11.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 248)) (2.11.7)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 255)) (2.33.2)\n",
            "Requirement already satisfied: pydantic-settings==2.9.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 257)) (2.9.1)\n",
            "Collecting pygments==2.19.2 (from -r requirements.txt (line 259))\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pypdf==5.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 261)) (5.6.0)\n",
            "Requirement already satisfied: pypika==0.48.9 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 263)) (0.48.9)\n",
            "Requirement already satisfied: pyproject-hooks==1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 265)) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 267)) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv==1.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 273)) (1.1.0)\n",
            "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 277)) (2025.2)\n",
            "Requirement already satisfied: pyyaml==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 279)) (6.0.2)\n",
            "Requirement already satisfied: referencing==0.36.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 288)) (0.36.2)\n",
            "Collecting requests==2.32.3 (from -r requirements.txt (line 292))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: requests-oauthlib==2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 305)) (2.0.0)\n",
            "Requirement already satisfied: requests-toolbelt==1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 307)) (1.0.0)\n",
            "Collecting rich==13.9.4 (from -r requirements.txt (line 309))\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: rpds-py==0.25.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 314)) (0.25.1)\n",
            "Requirement already satisfied: rsa==4.9.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 318)) (4.9.1)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 320)) (1.5.4)\n",
            "Requirement already satisfied: simsimd==6.4.9 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 322)) (6.4.9)\n",
            "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 324)) (1.17.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 330)) (1.3.1)\n",
            "Requirement already satisfied: sqlalchemy==2.0.41 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 332)) (2.0.41)\n",
            "Requirement already satisfied: sympy==1.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 336)) (1.14.0)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 338)) (0.9.0)\n",
            "Requirement already satisfied: tenacity==9.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 340)) (9.1.2)\n",
            "Requirement already satisfied: tokenizers==0.21.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 345)) (0.21.1)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 347)) (4.67.1)\n",
            "Requirement already satisfied: typer==0.16.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 351)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions==4.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 353)) (4.14.0)\n",
            "Requirement already satisfied: typing-inspect==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 370)) (0.9.0)\n",
            "Requirement already satisfied: typing-inspection==0.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 372)) (0.4.1)\n",
            "Requirement already satisfied: tzdata==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 376)) (2025.2)\n",
            "Collecting urllib3==2.1.0 (from -r requirements.txt (line 378))\n",
            "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: uvicorn==0.34.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]==0.34.3->-r requirements.txt (line 384)) (0.34.3)\n",
            "Requirement already satisfied: uvloop==0.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 386)) (0.21.0)\n",
            "Requirement already satisfied: watchfiles==1.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 388)) (1.1.0)\n",
            "Requirement already satisfied: websocket-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 390)) (1.8.0)\n",
            "Requirement already satisfied: websockets==15.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 392)) (15.0.1)\n",
            "Requirement already satisfied: yarl==1.20.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 394)) (1.20.1)\n",
            "Requirement already satisfied: zipp==3.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 396)) (3.23.0)\n",
            "Requirement already satisfied: zstandard==0.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 398)) (0.23.0)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
            "  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.13.5-py3-none-any.whl size=77231 sha256=bf87d896120216f6fc89b7188b9995cb470c02230c8a14d35fdc024177cf28fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/e9/dc/6a9c53e3740ebffd4c16b3da80fca2c6a9f9c4d08389b94cef\n",
            "  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.13.5-py3-none-any.whl size=661483 sha256=9a449b9c9833892c5d90b6db3cc6ace3b45c19ac29de2467137e6f11e58a601b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/cb/b9/cb962417cf3001085fab2117bd2e50041637713291188143ee\n",
            "  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.13.5-py3-none-any.whl size=90202 sha256=bdcefac15c6af6e62447fec0796c8d3297ecf5d322c2db6056d830ba1a0fe8e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/2f/68/a46aecfb40b81fa0cec6a3ec4a2fa49af1bf58674297f98c5d\n",
            "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
            "Installing collected packages: urllib3, pygments, numpy, fsspec, rich, requests, pandas, google-auth, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.1\n",
            "    Uninstalling numpy-2.3.1:\n",
            "      Successfully uninstalled numpy-2.3.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.5.1\n",
            "    Uninstalling fsspec-2025.5.1:\n",
            "      Successfully uninstalled fsspec-2025.5.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 14.0.0\n",
            "    Uninstalling rich-14.0.0:\n",
            "      Successfully uninstalled rich-14.0.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.40.3\n",
            "    Uninstalling google-auth-2.40.3:\n",
            "      Successfully uninstalled google-auth-2.40.3\n",
            "  Attempting uninstall: ibm-cos-sdk-core\n",
            "    Found existing installation: ibm-cos-sdk-core 2.14.2\n",
            "    Uninstalling ibm-cos-sdk-core-2.14.2:\n",
            "      Successfully uninstalled ibm-cos-sdk-core-2.14.2\n",
            "  Attempting uninstall: ibm-cos-sdk-s3transfer\n",
            "    Found existing installation: ibm-cos-sdk-s3transfer 2.14.2\n",
            "    Uninstalling ibm-cos-sdk-s3transfer-2.14.2:\n",
            "      Successfully uninstalled ibm-cos-sdk-s3transfer-2.14.2\n",
            "  Attempting uninstall: ibm-cos-sdk\n",
            "    Found existing installation: ibm-cos-sdk 2.14.2\n",
            "    Uninstalling ibm-cos-sdk-2.14.2:\n",
            "      Successfully uninstalled ibm-cos-sdk-2.14.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.3.2 google-auth-2.38.0 ibm-cos-sdk-2.13.5 ibm-cos-sdk-core-2.13.5 ibm-cos-sdk-s3transfer-2.13.5 numpy-2.0.2 pandas-2.2.2 pygments-2.19.2 requests-2.32.3 rich-13.9.4 urllib3-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "1bc5eb3c963543acb0e2d95b36bc0d3e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ad3159c-17ad-484e-99fb-779290902fe3"
      },
      "source": [
        "After you install the libraries, restart your kernel. You can do that by clicking the **Restart the kernel** icon.\n",
        "\n",
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/QrUNwLZfVySxQ9xvbOJgyQ/restart.png\" width=\"80%\" alt=\"Restart kernel\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c505ed06-ce94-460b-80b0-3b891bc4ea1f"
      },
      "source": [
        "### Defining helper functions\n",
        "\n",
        "_Use the following code to define some helper functions to reduce the repeat work in the notebook:_\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf4b05d6-00df-4c62-928a-a49b1fd99c70"
      },
      "outputs": [],
      "source": [
        "# You can use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c1efc98-e115-4bc3-b99d-379cb68fccdd"
      },
      "source": [
        "The following functions are prerequisite knowledge for understanding the topic of this project—retrievers. These functions include:\n",
        "\n",
        "- Building LLMs\n",
        "- Splitting documents into chunks\n",
        "- Building an embedding model\n",
        "\n",
        "The relevant knowledge and details of these functions have been covered in previous lessons.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d40dddc9-91b0-4ed7-b12d-ce76dcca4bfe"
      },
      "source": [
        "#### Build LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90962632-ebfd-44d2-ba67-973a6e24c9c8"
      },
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watsonx_ai import Credentials\n",
        "from ibm_watsonx_ai.foundation_models.extensions.langchain import WatsonxLLM"
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e3fd9bc-abb2-458c-af97-37e49ae32637"
      },
      "source": [
        "`mixtral-8x7b-instruct-v01` is used as the base foundational LLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99a11df1-61e7-4c72-a565-a1be3dc1906e"
      },
      "outputs": [],
      "source": [
        "def llm():\n",
        "    model_id = 'mistralai/mixtral-8x7b-instruct-v01'\n",
        "\n",
        "    import os\n",
        "    from getpass import getpass\n",
        "\n",
        "    from google.colab import userdata\n",
        "\n",
        "    ibm_api_key = userdata.get('IBM_API_KEY')\n",
        "    ibm_project_id = userdata.get('IBM_PROJECT_ID')\n",
        "\n",
        "    parameters = {\n",
        "        GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
        "        GenParams.TEMPERATURE: 0.5, # this randomness or creativity of the model's responses\n",
        "    }\n",
        "\n",
        "    credentials = {\n",
        "        \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
        "    }\n",
        "\n",
        "\n",
        "    project_id = \"skills-network\"\n",
        "\n",
        "    model = ModelInference(\n",
        "        model_id=model_id,\n",
        "        params=parameters,\n",
        "        credentials=credentials,\n",
        "        project_id=project_id,\n",
        "        apikey=ibm_api_key\n",
        "    )\n",
        "\n",
        "    mixtral_llm = WatsonxLLM(model = model)\n",
        "    return mixtral_llm"
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4044736d-4a18-477e-8779-6487e7adf8e4"
      },
      "source": [
        "#### Text splitter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "903d4e4b-d0e0-4692-8162-525e6e22dcac"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7842fac1-8c8e-46c0-b1f5-42da5daca52d"
      },
      "outputs": [],
      "source": [
        "def text_splitter(data, chunk_size, chunk_overlap):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(data)\n",
        "    return chunks"
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec5a10de-2492-49b4-b87a-5c85e57a9706"
      },
      "source": [
        "#### Embedding model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ed40cfb-6d51-4364-ab53-bb54ee742cf6"
      },
      "source": [
        "The following code demonstrates how to build an embedding model using the `watsonx.ai` package.\n",
        "\n",
        "For this project, the `ibm/slate-125m-english-rtrvr` embedding model is used.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c01fa1e-9424-43c8-8c41-f3b665b79345"
      },
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
        "from langchain_ibm import WatsonxEmbeddings"
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6af69096-c3ca-44d1-b251-664d014469fb"
      },
      "outputs": [],
      "source": [
        "def watsonx_embedding():\n",
        "\n",
        "    import os\n",
        "    from getpass import getpass\n",
        "\n",
        "    from google.colab import userdata\n",
        "\n",
        "    ibm_api_key = userdata.get('IBM_API_KEY')\n",
        "    ibm_project_id = userdata.get('IBM_PROJECT_ID')\n",
        "    embed_params = {\n",
        "        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
        "        EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
        "    }\n",
        "\n",
        "    watsonx_embedding = WatsonxEmbeddings(\n",
        "        model_id=\"ibm/slate-125m-english-rtrvr\",\n",
        "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "        project_id=ibm_project_id,\n",
        "        apikey=ibm_api_key,\n",
        "        params=embed_params,\n",
        "    )\n",
        "    return watsonx_embedding"
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce805475-a941-451b-82c1-a31d57078f9a"
      },
      "source": [
        "## Retrievers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "240c06fd-8257-47a9-bf8d-d0cdd24c5707"
      },
      "source": [
        "A retriever is an interface designed to return documents based on an unstructured query. Unlike a vector store, which stores and retrieves documents, a retriever's primary function is to find and return relevant documents. While vector stores can serve as the backbone of a retriever, there are various other types of retrievers that can be used as well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "302b7c7d-9849-4482-93ec-bd1f10dfa95c"
      },
      "source": [
        "Retrievers take a string `query` as input and output a list of `Documents`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce2b059d-4d94-4d59-98f6-5b229cd14e6a"
      },
      "source": [
        "### Vector Store-Backed Retriever\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0a68e80-289d-4745-8c85-27cb4c7e6824"
      },
      "source": [
        "A vector store retriever is a type of retriever that utilizes a vector store to fetch documents. It acts as a lightweight wrapper around the vector store class, enabling it to conform to the retriever interface. This retriever leverages the search methods implemented by the vector store, such as similarity search and Maximum Marginal Relevance (MMR), to query texts stored within it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eebefaa-c0b8-4c48-973c-cbd93e81a463"
      },
      "source": [
        "Before demonstrating this retriever, you need to load some example text. A `.txt` document has been prepared for you.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8656acb5-af5f-41da-ad7e-411507fd8308",
        "outputId": "0fc94949-79c3-4584-c7e1-974b86c2847b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-21 13:47:37--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/MZ9z1lm-Ui3YBp3SYWLTAQ/companypolicies.txt\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15660 (15K) [text/plain]\n",
            "Saving to: ‘companypolicies.txt.1’\n",
            "\n",
            "\rcompanypolicies.txt   0%[                    ]       0  --.-KB/s               \rcompanypolicies.txt 100%[===================>]  15.29K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-06-21 13:47:37 (174 MB/s) - ‘companypolicies.txt.1’ saved [15660/15660]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/MZ9z1lm-Ui3YBp3SYWLTAQ/companypolicies.txt\""
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11473a06-2d75-43f9-9e95-2936ee00feca"
      },
      "source": [
        "Use `TextLoader` to load the document.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3994a0e5-80f9-422a-9b66-6b49f0e14b17"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader"
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c24ff2b-b133-4f5a-8217-7eeaf2cd73f5"
      },
      "outputs": [],
      "source": [
        "loader = TextLoader(\"companypolicies.txt\")\n",
        "txt_data = loader.load()"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d5da3a9-86c2-4549-98cb-90dae9a28a55"
      },
      "source": [
        "Let's take a look at this document. This is a document about different policies in a company.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9f35bbd-cb68-4a4e-a7f3-87fadf2e6579",
        "outputId": "f91d79f1-92b8-4834-ea2c-b2a322791dc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'companypolicies.txt'}, page_content=\"1.\\tCode of Conduct\\n\\nOur Code of Conduct outlines the fundamental principles and ethical standards that guide every member of our organization. We are committed to maintaining a workplace that is built on integrity, respect, and accountability.\\nIntegrity: We hold ourselves to the highest ethical standards. This means acting honestly and transparently in all our interactions, whether with colleagues, clients, or the broader community. We respect and protect sensitive information, and we avoid conflicts of interest.\\nRespect: We embrace diversity and value each individual's contributions. Discrimination, harassment, or any form of disrespectful behavior is unacceptable. We create an inclusive environment where differences are celebrated and everyone is treated with dignity and courtesy.\\nAccountability: We take responsibility for our actions and decisions. We follow all relevant laws and regulations, and we strive to continuously improve our practices. We report any potential violations of this code and support the investigation of such matters.\\nSafety: We prioritize the safety of our employees, clients, and the communities we serve. We maintain a culture of safety, including reporting any unsafe conditions or practices.\\nEnvironmental Responsibility: We are committed to minimizing our environmental footprint and promoting sustainable practices.\\nOur Code of Conduct is not just a set of rules; it is the foundation of our organization's culture. We expect all employees to uphold these principles and serve as role models for others, ensuring we maintain our reputation for ethical conduct, integrity, and social responsibility.\\n\\n2.\\tRecruitment Policy\\n\\nOur Recruitment Policy reflects our commitment to attracting, selecting, and onboarding the most qualified and diverse candidates to join our organization. We believe that the success of our company relies on the talents, skills, and dedication of our employees.\\nEqual Opportunity: We are an equal opportunity employer and do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or any other protected status. We actively promote diversity and inclusion.\\nTransparency: We maintain transparency in our recruitment processes. All job vacancies are advertised internally and externally when appropriate. Job descriptions and requirements are clear and accurately represent the role.\\nSelection Criteria: Our selection process is based on the qualifications, experience, and skills necessary for the position. Interviews and assessments are conducted objectively, and decisions are made without bias.\\nData Privacy: We are committed to protecting the privacy of candidates' personal information and adhere to all relevant data protection laws and regulations.\\nFeedback: Candidates will receive timely and constructive feedback on their application and interview performance.\\nOnboarding: New employees receive comprehensive onboarding to help them integrate into the organization effectively. This includes information on our culture, policies, and expectations.\\nEmployee Referrals: We encourage and appreciate employee referrals as they contribute to building a strong and engaged team.\\nOur Recruitment Policy is a foundation for creating a diverse, inclusive, and talented workforce. It ensures that we attract and hire the best candidates who align with our company values and contribute to our continued success. We continuously review and update this policy to reflect evolving best practices in recruitment.\\n\\n3.\\tInternet and Email Policy\\n\\nOur Internet and Email Policy is established to guide the responsible and secure use of these essential tools within our organization. We recognize their significance in daily business operations and the importance of adhering to principles that maintain security, productivity, and legal compliance.\\nAcceptable Use: Company-provided internet and email services are primarily meant for job-related tasks. Limited personal use is allowed during non-work hours, provided it doesn't interfere with work responsibilities.\\nSecurity: Safeguard your login credentials, avoiding the sharing of passwords. Exercise caution with email attachments and links from unknown sources. Promptly report any unusual online activity or potential security breaches.\\nConfidentiality: Reserve email for the transmission of confidential information, trade secrets, and sensitive customer data only when encryption is applied. Exercise discretion when discussing company matters on public forums or social media.\\nHarassment and Inappropriate Content: Internet and email usage must not involve harassment, discrimination, or the distribution of offensive or inappropriate content. Show respect and sensitivity to others in all online communications.\\nCompliance: Ensure compliance with all relevant laws and regulations regarding internet and email usage, including those related to copyright and data protection.\\nMonitoring: The company retains the right to monitor internet and email usage for security and compliance purposes.\\nConsequences: Policy violations may lead to disciplinary measures, including potential termination.\\nOur Internet and Email Policy aims to promote safe, responsible usage of digital communication tools that align with our values and legal obligations. Each employee is expected to understand and follow this policy. Regular reviews ensure its alignment with evolving technology and security standards.\\n\\n4.\\tMobile Phone Policy\\n\\nThe Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\\nAcceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\\nSecurity: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\\nConfidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.\\nCost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\\nCompliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\\nLost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\\nConsequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\\nThe Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices.\\n\\n5.\\tSmoking Policy\\n\\nPolicy Purpose: The Smoking Policy has been established to provide clear guidance and expectations concerning smoking on company premises. This policy is in place to ensure a safe and healthy environment for all employees, visitors, and the general public.\\nDesignated Smoking Areas: Smoking is only permitted in designated smoking areas, as marked by appropriate signage. These areas have been chosen to minimize exposure to secondhand smoke and to maintain the overall cleanliness of the premises.\\nSmoking Restrictions: Smoking inside company buildings, offices, meeting rooms, and other enclosed spaces is strictly prohibited. This includes electronic cigarettes and vaping devices.\\nCompliance with Applicable Laws: All employees and visitors must adhere to relevant federal, state, and local smoking laws and regulations.\\nDisposal of Smoking Materials: Properly dispose of cigarette butts and related materials in designated receptacles. Littering on company premises is prohibited.\\nNo Smoking in Company Vehicles: Smoking is not permitted in company vehicles, whether they are owned or leased, to maintain the condition and cleanliness of these vehicles.\\nEnforcement and Consequences: All employees and visitors are expected to adhere to this policy. Non-compliance may lead to appropriate disciplinary action, which could include fines, or, in the case of employees, possible termination of employment.\\nReview of Policy: This policy will be reviewed periodically to ensure its alignment with evolving legal requirements and best practices for maintaining a healthy and safe workplace.\\nWe appreciate your cooperation in maintaining a smoke-free and safe environment for all.\\n\\n6.\\tDrug and Alcohol Policy\\n\\nPolicy Objective: The Drug and Alcohol Policy is established to establish clear expectations and guidelines for the responsible use of drugs and alcohol within the organization. This policy aims to maintain a safe, healthy, and productive workplace.\\nProhibited Substances: The use, possession, distribution, or sale of illegal drugs or unauthorized controlled substances is strictly prohibited on company premises or during work-related activities. This includes the misuse of prescription drugs.\\nAlcohol Consumption: The consumption of alcoholic beverages is not allowed during work hours, on company property, or while performing company-related duties. Exception may be made for company-sanctioned events.\\nImpairment: Employees are expected to perform their job duties without impairment from drugs or alcohol. The use of substances that could impair job performance or pose a safety risk is prohibited.\\nTesting and Searches: The organization reserves the right to conduct drug and alcohol testing as per applicable laws and regulations. Employees may be subject to testing in cases of reasonable suspicion, post-accident, or as part of routine workplace safety measures.\\nReporting: Employees should report any concerns related to drug or alcohol misuse by themselves or their colleagues, as well as safety concerns arising from such misuse.\\nTreatment and Assistance: Employees with substance abuse issues are encouraged to seek help. The organization is committed to providing support, resources, and information to assist those seeking treatment.\\nConsequences: Violation of this policy may result in disciplinary actions, up to and including termination of employment. Legal action may also be pursued when necessary.\\nPolicy Review: This policy will undergo periodic review to ensure its continued relevance and compliance with evolving legal requirements and best practices for a safe and productive work environment.\\nYour adherence to this policy is appreciated as it helps to maintain a safe and drug-free workplace for all.\\n\\n7.\\tHealth and Safety Policy\\n\\nOur commitment to health and safety is paramount. We prioritize the well-being of our employees, customers, and the public. We diligently comply with all relevant health and safety laws and regulations. Our objective is to maintain a workplace free from hazards, preventing accidents, injuries, and illnesses. Every individual within our organization is responsible for upholding these standards. We regularly assess and improve our safety measures, provide adequate training, and encourage open communication regarding safety concerns. Through collective dedication, we aim to ensure a safe, healthy, and secure environment for all. Your cooperation is essential in achieving this common goal.\\n\\n8.\\tAnti-discrimination and Harassment Policy\\n\\nThe Anti-Discrimination and Harassment Policy is a testament to the commitment of this organization in fostering a workplace that is free from discrimination, harassment, and any form of unlawful bias. This policy applies to every individual within the organization, including employees, contractors, visitors, and clients.\\nNon-Discrimination: This organization strictly prohibits discrimination based on race, color, religion, gender, national origin, age, disability, sexual orientation, or any other legally protected characteristic in all aspects of employment, including recruitment, hiring, compensation, benefits, promotions, and terminations.\\nHarassment: Harassment in any form, whether based on the aforementioned characteristics or any other protected status, is unacceptable. This encompasses unwelcome advances, offensive jokes, slurs, and other verbal or physical conduct that creates a hostile or intimidating work environment.\\nReporting: Individuals who experience or witness any form of discrimination or harassment are encouraged to promptly report the incident to their supervisor, manager, or the designated HR representative. The organization is committed to a timely and confidential investigation of such complaints.\\nConsequences: Violation of this policy may result in disciplinary action, including termination of employment. The organization is committed to taking appropriate action against any individual found to be in violation of this policy.\\nReview and Update: This policy is subject to regular review and update to remain aligned with evolving legal requirements and best practices in preventing discrimination and harassment. This organization considers it a collective responsibility to ensure a workplace free from discrimination and harassment, and it is essential that every individual within the organization plays their part in upholding these principles.\\n\\n9.\\tDiscipline and Termination Policy\\n\\nThe Discipline and Termination Policy underscores the organization's commitment to maintaining a productive, ethical, and respectful work environment. This policy applies to all personnel, including employees, contractors, and temporary staff.\\nPerformance and Conduct Expectations: Employees are expected to meet performance standards and adhere to conduct guidelines. The organization will provide clear expectations, feedback, and opportunities for improvement when performance or conduct issues arise.\\nDisciplinary Actions: When necessary, disciplinary actions will be taken, which may include verbal warnings, written warnings, suspension, or other appropriate measures. Disciplinary actions are designed to address issues constructively and maintain performance standards.\\nTermination: In situations where an employee's performance or conduct issues persist, the organization may resort to termination. Termination may also occur for reasons such as redundancy, violation of policies, or restructuring.\\nTermination Procedure: The organization will follow appropriate procedures, ensuring fairness and adherence to legal requirements during the termination process. Employees may be eligible for notice periods, severance pay, or other benefits as per employment agreements and applicable laws.\\nExit Process: The organization will conduct an exit process to ensure a smooth transition for departing employees, including the return of company property, final pay, and cancellation of access and benefits.\\nThis policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after careful consideration. Every employee is expected to understand and adhere to this policy, contributing to a respectful and productive workplace. Regular reviews will ensure its alignment with evolving legal requirements and best practices.\\n\")]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "txt_data"
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c154f3c3-fcdb-4bb9-b0f7-1629ce3dcb29"
      },
      "source": [
        "Split `txt_data` into chunks. `chunk_size = 200`, `chunk_overlap = 20` has been set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f044d98-743b-43d3-8368-02d07d1fdba3"
      },
      "outputs": [],
      "source": [
        "chunks_txt = text_splitter(txt_data, 200, 20)"
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b6a1eb9-9d20-4901-a8fc-d14408cf4b3f"
      },
      "source": [
        "Store the embeddings into a `ChromaDB`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad3df61b-db4d-4320-94de-33f5c6b4c40a"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ad29c0-1297-4060-a219-23e357e03b71"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(chunks_txt, watsonx_embedding())"
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c88f2ca-ecfc-4d59-abca-39bfabe8fe72"
      },
      "source": [
        "#### Simple similarity search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84d750dd-0029-41ec-aa61-c3649bb18a6e"
      },
      "source": [
        "Here is an example of a simple similarity search based on the vector database.\n",
        "\n",
        "For this demonstration, the query has been set to \"email policy\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "146a3110-8322-46d2-89e4-86e516f7c077"
      },
      "outputs": [],
      "source": [
        "query = \"email policy\"\n",
        "retriever = vectordb.as_retriever()"
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34bd3fb0-f612-4754-b81c-19ae04cd9756"
      },
      "outputs": [],
      "source": [
        "docs = retriever.invoke(query)"
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffe4d29d-59fa-4b2b-b9c2-5f30d0e60a3f"
      },
      "source": [
        "By default, the number of retrieval results is four, and they are ranked by similarity level.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e14880f-83b7-4c15-ae66-45caa4d643c7",
        "outputId": "62c5bb20-6514-4679-ea99-a59ffa67e206"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after'),\n",
              " Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy aims to maintain a safe, healthy, and productive workplace.'),\n",
              " Document(metadata={'source': 'companypolicies.txt'}, page_content='will ensure its alignment with evolving legal requirements and best practices.'),\n",
              " Document(metadata={'source': 'companypolicies.txt'}, page_content='Review of Policy: This policy will be reviewed periodically to ensure its alignment with evolving legal requirements and best practices for maintaining a healthy and safe workplace.')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "docs"
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45870c8d-f7ba-4ff2-b96b-aee5c75781b0"
      },
      "source": [
        "You can also specify `search kwargs` like `k` to limit the retrieval results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32128764-5973-404c-ad14-b86357185ed6",
        "outputId": "4a0ff154-d7c0-4ee5-a697-5055b7a81222"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 1})\n",
        "docs = retriever.invoke(query)\n",
        "docs"
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "039e8f83-464a-4540-8b84-f16521b33cdd"
      },
      "source": [
        "#### MMR retrieval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "378a3749-5cc3-4301-b0de-16aac5cad02b"
      },
      "source": [
        "MMR in vector stores is a technique used to balance the relevance and diversity of retrieved results. It selects documents that are both highly relevant to the query and minimally similar to previously selected documents. This approach helps to avoid redundancy and ensures a more comprehensive coverage of different aspects of the query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc5c7036-153e-4560-8040-27d17c607185"
      },
      "source": [
        "The following code is showing how to conduct an MMR search in a vector database. You just need to sepecify `search_type=\"mmr\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify your vectordb has embeddings\n",
        "print(f\"Number of documents: {vectordb._collection.count()}\")\n",
        "\n",
        "# Test with a simple similarity search first\n",
        "test_docs = vectordb.similarity_search(\"test query\", k=1)\n",
        "print(f\"Test search works: {len(test_docs) > 0}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGSXsN45qwAN",
        "outputId": "7f650282-3295-4de9-b012-ee3cced81115"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 122\n",
            "Test search works: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Try with explicit MMR parameters\n",
        "retriever = vectordb.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\n",
        "        \"k\": 4,\n",
        "        \"fetch_k\": 20,\n",
        "        \"lambda_mult\": 0.7\n",
        "    }\n",
        ")\n",
        "docs = retriever.invoke(query)\n"
      ],
      "metadata": {
        "id": "z7FLt6KGqDhe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dksge6GCwGd9",
        "outputId": "8e14ab55-c496-4c70-e6fc-b01daed3579c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after'),\n",
              " Document(metadata={'source': 'companypolicies.txt'}, page_content='including employees, contractors, and temporary staff.'),\n",
              " Document(metadata={'source': 'companypolicies.txt'}, page_content=\"Data Privacy: We are committed to protecting the privacy of candidates' personal information and adhere to all relevant data protection laws and regulations.\"),\n",
              " Document(metadata={'source': 'companypolicies.txt'}, page_content='We appreciate your cooperation in maintaining a smoke-free and safe environment for all.')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "720670b7-1d40-437a-adde-c88ef3e837d0"
      },
      "source": [
        "#### Similarity score threshold retrieval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1333591d-a1fe-49ce-80b7-489aa0c9d183"
      },
      "source": [
        "You can also set a retrieval method that defines a similarity score threshold, returning only documents with a score above that threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52eb94d3-ff17-47e7-be5a-06c9648f49d8",
        "outputId": "4e245327-2afe-4255-b4a3-f8798cdf8f7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after'),\n",
              " Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy aims to maintain a safe, healthy, and productive workplace.')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "retriever = vectordb.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.4}\n",
        ")\n",
        "docs = retriever.invoke(query)\n",
        "docs"
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed9e66ed-f409-4255-8743-f71bfff38024"
      },
      "source": [
        "### Multi-Query Retriever\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da8c81cb-dd52-4312-9b67-801109c9d86a"
      },
      "source": [
        "Distance-based vector database retrieval represents queries in high-dimensional space and finds similar embedded documents based on \"distance\". However, retrieval results may vary with subtle changes in query wording or if the embeddings do not accurately capture the data's semantics.\n",
        "\n",
        "The `MultiQueryRetriever` addresses this by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and then takes the unique union of these results to form a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the `MultiQueryRetriever` can potentially overcome some limitations of distance-based retrieval, resulting in a richer and more diverse set of results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "402dc868-b7d9-4d9b-97d6-1a7a59148af7"
      },
      "source": [
        "The following picture shows the difference between retrievers solely based on distance and the Multi-Query Retriever.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98c69c6a-8202-49e2-b860-502367f6d9f1"
      },
      "source": [
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/NCZCJ26bp3uKTa0gp8Agwg/multiquery.png\" width=\"40%\" alt=\"multiquery\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed6ee04e-03ec-43c1-8051-640c7857d39f"
      },
      "source": [
        "Let's consider the query sentence, `\"I like cats\"`.\n",
        "\n",
        "On the upper side of the picture, you can see a retriever that relies solely on distance. This retriever calculates the distance between the query and the documents in the vector store, returning the document with the closest match.\n",
        "\n",
        "On the lower side, you can see a multi-query retriever. It first uses an LLM to generate multiple queries from different perspectives based on the user's input query. For each generated query, it retrieves relevant documents and then returns the union of these results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68784729-dc7d-4c7f-ba84-d76eb812d95e"
      },
      "source": [
        "A PDF document has been prepared to demonstrate this Multi-Query Retriever.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aabb9fb-aa14-47ae-994c-73f1bf88d897"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0865a705-fb01-47d5-bfaa-6a3b5634eb9c"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf\")\n",
        "pdf_data = loader.load()"
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d83ecaa-2f6f-41fa-90a8-33bcfe7d1520"
      },
      "source": [
        "Let's take a look at the first page of this paper. This paper is talking about the framework LangChain.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ea168c-46e6-4414-a467-b030075d2b15",
        "outputId": "9c825312-0fca-4bc8-f70c-1ac3b2d1fa84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='LangChain helps us to unlock the ability to harness the \\nLLM’s immense potential in tasks such as document analysis, \\nchatbot development, code analysis, and countless other \\napplications. Whether your desire is to unlock deeper natural \\nlanguage understanding , enhance data, or circumvent \\nlanguage barriers through translation, LangChain is ready to \\nprovide the tools and programming support you need to do \\nwithout it that it is not only difficult but also fresh for you. Its \\ncore functionalities encompass: \\n1. Context-Aware Capabilities: LangChain facilitates the \\ndevelopment of applications that are inherently \\ncontext-aware. This means that these applications can \\nconnect to a language model and draw from various \\nsources of context, such as prompt instructions, a few-\\nshot examples, or existing content, to ground their \\nresponses effectively. \\n2. Reasoning Abilities: LangChain equips applications \\nwith the capacity to reason effectively. By relying on a \\nlanguage model, these applications can make informed \\ndecisions about how to respond based on the provided \\ncontext and determine the appropriate actions to take. \\nLangChain offers several key value propositions: \\nModular Components: It provides abstractions that \\nsimplify working with language models, along with a \\ncomprehensive collection of implementations for each \\nabstraction. These components are designed to be modular \\nand user -friendly, making them useful whethe r you are \\nutilizing the entire LangChain framework or not. \\nOff-the-Shelf Chains: LangChain offers pre -configured \\nchains, which are structured assemblies of components \\ntailored to accomplish specific high -level tasks. These pre -\\ndefined chains streamline the initial setup process and serve as \\nan ideal starting point for your projects. The MindGuide Bot \\nuses below components from LangChain. \\nA. ChatModel \\nWithin LangChain, a ChatModel is a specific kind of \\nlanguage model crafted to manage conversational \\ninteractions. Unlike traditional language models that take one \\nstring as input and generate a single string as output, \\nChatModels operate with a list of mes sages as input, \\ngenerating a message as output. \\nEach message in the list has two parts: the content and the \\nrole. The content is the actual text or substance of the message, \\nwhile the role denotes the role or source of the message (such \\nas \"User,\" \"Assistant,\" \"System,\" etc.). \\nThis approach with ChatModels opens the door to more \\ndynamic and interactive conversations with the language \\nmodel. It empowers the creation of chatbot applications, \\ncustomer support systems, or any other application involving \\nmulti-turn conversations. We utilized the ChatOpenAI \\nChatModel to create MindGuide chatbots specifically \\ndesigned to function as mental health therapists. In our \\ninteraction with OpenAI, we opted for an OpenAI API key to \\nengage with the ChatGpt3 turbo model and utilized a \\ntemperature value of 0.5. The steps to create an OpenAI API \\nkey are outlined [9].  \\nB. Message \\nIn the context of LangChain, messages  [10] refer to a list of \\nmessages that are used as input when interacting with a \\nChatModel. Each message in the list represents a specific turn \\nor exchange in a conversation. Each message in the messages \\nlist typically consists of two components: \\n• content: This represents the actual text or content of \\nthe message. It can be a user query, a system \\ninstruction, or any other relevant information. \\n• role: This represents the role or source of the \\nmessage. It defines who is speaking or generating \\nthe message. Common roles include \"User\", \\n\"Assistant\", \"System\", or any other custom role you \\ndefine. \\nThe chat model interface is based around messages rather \\nthan raw text. The types of messages supported in LangChain \\nare SystenMessage, HumanMessage, and AIMessage. \\nSystemMessage is the ChatMessage coming from the system \\nin its LangChain template  as illustrated in Figure 1. Human \\nMessage is a  ChatMessage coming from a human/user.  \\nAIMessage is a ChatMessage coming from an AI/assistant as \\nillustrated in Figure 2.  \\n \\n                   Figure 1. A System Message illustration  \\nYou are a compassionate and experienced mental \\nhealth therapist with a proven track record of \\nhelping patients overcome anxiety and other mental \\nhealth challenges. Your primary objective is to \\nsupport the patient in addressing their concerns \\nand guiding them towards positive change. In this \\ninteractive therapy session, you will engage with \\nthe patient by asking open -ended questions, \\nactively listening to their responses, and providing \\nempathetic feedback. Your approach is \\ncollaborative, and you strive to cr eate a safe and \\nnon-judgmental space for the patient to share their \\nthoughts and feelings. \\nAs the patient shares their struggles, you will \\nprovide insightful guidance and evidence -based \\nstrategies tailored to their unique needs. You may \\nalso offer practical exercises or resources to help \\nthem manage their symptoms and improve their \\nmental wellbeing. When necessary, you will gently \\nredirect the conversation back to the patient\\'s \\nprimary concerns related to anxiety, mental health, \\nor family issues. This ensures that each session is \\nproductive and focused on addressing the most \\npressing issues. Thro ughout the session, you \\nremain mindful of the patient\\'s emotional state and \\nadjust your approach accordingly. \\nYou recognize that everyone\\'s journey is \\ndifferent, and that progress can be incremental.  \\nBy building trust and fostering a strong \\ntherapeutic relationship, you empower the patient \\nto take ownership of their growth and development. \\nAt the end of the session, you will summarize key \\npoints from your discussion, highlighting the \\npatient\\'s strengths and areas for improvement. \\nTogether, you will set achievable goals for future \\nsessions, reinforcing a sense of hope and \\nmotivation. Your ultimate goal is to equip the \\npatient with the tools and skills needed to navigate \\nlife\\'s challenges with confidence and resilience.')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "pdf_data[1]"
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deca5a54-8bfd-4219-90cb-da214695a3f8"
      },
      "source": [
        "Split document and store the embeddings into a vector database.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ded3073b-ef27-4b4b-bba8-4e625a3d69ac"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "chunks_pdf = text_splitter(pdf_data, 500, 20)\n",
        "\n",
        "# VectorDB\n",
        "ids = vectordb.get()[\"ids\"]\n",
        "vectordb.delete(ids) # We need to delete existing embeddings from previous documents and then store current document embeddings in.\n",
        "vectordb = Chroma.from_documents(documents=chunks_pdf, embedding=watsonx_embedding())"
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d310b649-615b-4df1-b58e-2675316e0eed"
      },
      "source": [
        "The `MultiQueryRetriever` function from LangChain is used.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "\n",
        "    ibm_api_key = userdata.get('IBM_API_KEY')\n",
        "    ibm_project_id = userdata.get('IBM_PROJECT_ID')\n",
        "except:\n",
        "    ibm_api_key = getpass(\"Enter your IBM_API_KEY: \")\n",
        "\n",
        "# Set up IBM credentials\n",
        "os.environ[\"WATSONX_APIKEY\"] = ibm_api_key\n",
        "os.environ[\"WATSONX_PROJECT_ID\"] = ibm_project_id"
      ],
      "metadata": {
        "id": "TGyJqIygwy5P"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_ibm import WatsonxLLM\n",
        "def llm():\n",
        "    return WatsonxLLM(\n",
        "        model_id=\"google/flan-t5-xl\",\n",
        "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "        project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n",
        "        apikey=ibm_api_key,\n",
        "        params={\n",
        "            \"decoding_method\": \"greedy\",\n",
        "            \"max_new_tokens\": 200,\n",
        "            \"temperature\": 0,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Create the multi-query retriever\n",
        "retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=vectordb.as_retriever(search_type=\"similarity\"),\n",
        "    llm=llm()\n",
        ")\n",
        "\n",
        "# Use it\n",
        "query = \"What does the paper say about langchain?\"\n",
        "docs = retriever.invoke(query)"
      ],
      "metadata": {
        "id": "yBDB91GFyhtq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ef285ec-7486-45cd-a471-adc9c9cd8602"
      },
      "source": [
        "Set logging for the queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37c560aa-4a9f-44d5-9efd-86612a8fd5e7"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
      ],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b84ad35f-e019-4a2e-848a-fdc167ceb326",
        "outputId": "429be885-5828-4f8e-c7ef-50d42d0e60f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['What does the paper say about a tuple?']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'creator': 'Microsoft Word', 'total_pages': 6, 'page': 0, 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'producer': 'PyPDF', 'author': 'IEEE', 'creationdate': '2023-12-31T03:50:13+00:00', 'moddate': '2023-12-31T03:52:06+00:00', 'page_label': '1', 'title': 's8329 final'}, page_content='Additionally, the paper discusses the implementation of \\nStreamlit to enhance the user ex perience and interaction with \\nthe chatbot. Th is novel approach holds great promise for \\nproactive mental health intervention and assistance. \\nKeywords —Large Language models , LangChain, Chatbot, \\nPretrained models, Mental health, Mental health support. \\nI. INTRODUCTION \\nThe issue of mental health is an international situation, \\naffecting people in each particularly developed nations and'),\n",
              " Document(metadata={'author': 'IEEE', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'total_pages': 6, 'page_label': '2', 'creator': 'Microsoft Word', 'page': 1, 'creationdate': '2023-12-31T03:50:13+00:00', 'producer': 'PyPDF', 'moddate': '2023-12-31T03:52:06+00:00'}, page_content='the message. It can be a user query, a system \\ninstruction, or any other relevant information. \\n• role: This represents the role or source of the \\nmessage. It defines who is speaking or generating \\nthe message. Common roles include \"User\", \\n\"Assistant\", \"System\", or any other custom role you \\ndefine. \\nThe chat model interface is based around messages rather \\nthan raw text. The types of messages supported in LangChain \\nare SystenMessage, HumanMessage, and AIMessage.'),\n",
              " Document(metadata={'creator': 'Microsoft Word', 'page_label': '1', 'creationdate': '2023-12-31T03:50:13+00:00', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'author': 'IEEE', 'producer': 'PyPDF', 'total_pages': 6, 'page': 0}, page_content='the use of contextualized pretrained language models  [4], \\nwhich have garnered substantial attention for their \\neffectiveness in various text processing tasks. \\nThis paper delves into the application of these recent \\nadvancements in pretrained contextualized large language \\nmodels to introduce MindGuide, an innovative chatbot \\ndesigned to function as a mental health assistant for \\nindividuals in need of guidance and support in these critical'),\n",
              " Document(metadata={'page': 1, 'page_label': '2', 'producer': 'PyPDF', 'total_pages': 6, 'creationdate': '2023-12-31T03:50:13+00:00', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ioch1wsxkfqgfLLgmd-6Rw/langchain-paper.pdf', 'creator': 'Microsoft Word', 'moddate': '2023-12-31T03:52:06+00:00', 'author': 'IEEE', 'title': 's8329 final'}, page_content='utilizing the entire LangChain framework or not. \\nOff-the-Shelf Chains: LangChain offers pre -configured \\nchains, which are structured assemblies of components \\ntailored to accomplish specific high -level tasks. These pre -\\ndefined chains streamline the initial setup process and serve as \\nan ideal starting point for your projects. The MindGuide Bot \\nuses below components from LangChain. \\nA. ChatModel \\nWithin LangChain, a ChatModel is a specific kind of')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "docs = retriever.invoke(query)\n",
        "docs"
      ],
      "execution_count": 37
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efe269c1-6653-4201-9fde-226d234aa9e2"
      },
      "source": [
        "From the log results, you can see that the LLM generated three additional queries from different perspectives based on the given query.\n",
        "\n",
        "The returned results are the union of the results from each query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b8a45e6-6fd6-41e8-b33a-92b931909f2a"
      },
      "source": [
        "### Self-Querying Retriever\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae0b536c-7ce3-4bab-b2ac-8c980bab8d5c"
      },
      "source": [
        "A Self-Querying Retriever, as the name suggests, has the ability to query itself. Specifically, given a natural language query, the retriever uses a query-constructing LLM chain to generate a structured query. It then applies this structured query to its underlying vector store. This enables the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but also to extract and apply filters based on the metadata of those documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b813623-9042-4cfc-934d-87e8bbd91dfa"
      },
      "source": [
        "The following code demonstrates how to use a Self-Querying Retriever.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6fb3fad-85db-4c13-8c33-9c13d1a05105"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from lark import lark"
      ],
      "execution_count": 38
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab46f8b0-2343-456c-9f96-f3985a73d748"
      },
      "source": [
        "A couple of document pieces have been prepared where the `page_content` contains descriptions of movies, and the `meta_data` includes different attributes for each movie, such as `year`, `rating`, `genre`, and `director`. These attributes are crucial in the Self-Querying Retriever, as the LLM will use the metadata information to apply filters during the retrieval process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ca1a27d-c476-4195-a794-b3a5e8a581dc"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
        "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
        "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
        "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
        "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Toys come alive and have a blast doing so\",\n",
        "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
        "        metadata={\n",
        "            \"year\": 1979,\n",
        "            \"director\": \"Andrei Tarkovsky\",\n",
        "            \"genre\": \"thriller\",\n",
        "            \"rating\": 9.9,\n",
        "        },\n",
        "    ),\n",
        "]"
      ],
      "execution_count": 39
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86e5a4a2-13a7-476f-b0af-41ea16bc64e4"
      },
      "source": [
        "Now you can instantiate your retriever. To do this, you'll need to provide some upfront information about the metadata fields that your documents support, as well as a brief description of the document contents.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3288792d-080c-481f-9284-9f6d7225fd66"
      },
      "outputs": [],
      "source": [
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"genre\",\n",
        "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"year\",\n",
        "        description=\"The year the movie was released\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"director\",\n",
        "        description=\"The name of the movie director\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
        "    ),\n",
        "]"
      ],
      "execution_count": 40
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d755740-b4e9-4d40-a8b0-185a3888bfe3"
      },
      "source": [
        "Store the document's embeddings into a vector database.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a4085cf-a9b0-479e-8c3b-2cabed657204"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(docs, watsonx_embedding())"
      ],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74a69f13-d152-497e-9502-6ee7902ef3a3"
      },
      "source": [
        "Use the `SelfQueryRetriever`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72f9130b-d97c-4f24-8b70-2942e8a215f6"
      },
      "outputs": [],
      "source": [
        "document_content_description = \"Brief summary of a movie.\"\n",
        "\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm(),\n",
        "    vectordb,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        ")"
      ],
      "execution_count": 42
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86a43dda-9ebc-4ad7-a5f3-69ac87886977"
      },
      "source": [
        "Now you can actually try using your retriever.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "79a6fee1-fffd-432c-8a08-2102e781a17b",
        "outputId": "10a0c58c-f209-494b-ca29-60065206e2bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutputParserException",
          "evalue": "Parsing text\njson  \"query\": \"movie summary\", \"filter\": \"rating > 8.5\"\n raised following error:\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mjson_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mjson_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_string\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36m_parse_json\u001b[0;34m(json_str, parser)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# Parse the JSON string into a Python dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# for the original string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mallowed_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"limit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_and_check_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Got invalid JSON object. Error: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpected_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-43-3645456786.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This example only specifies a filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I want to watch a movie rated higher than 8.5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_other_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 result = self._get_relevant_documents(\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/retrievers/self_query/base.py\u001b[0m in \u001b[0;36m_get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrelevant\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         structured_query = self.query_constructor.invoke(\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5429\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5430\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5431\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5432\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5433\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mrun_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"parser\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             )\n\u001b[0;32m--> 204\u001b[0;31m         return self._call_with_config(\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 output = cast(\n\u001b[1;32m   1939\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1941\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    203\u001b[0m             )\n\u001b[1;32m    204\u001b[0m         return self._call_with_config(\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mStructured\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     64\u001b[0m             )\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             raise OutputParserException(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0;34mf\"Parsing text\\n{text}\\n raised following error:\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             )\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Parsing text\njson  \"query\": \"movie summary\", \"filter\": \"rating > 8.5\"\n raised following error:\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
          ]
        }
      ],
      "source": [
        "# This example only specifies a filter\n",
        "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
      ],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4a7c73a-4812-411a-b663-6a7f5dfbbc39"
      },
      "outputs": [],
      "source": [
        "# This example specifies a query and a filter\n",
        "retriever.invoke(\"Has Greta Gerwig directed any movies about women\")"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2876f25-bca1-4afd-a9c5-3698ae96c945"
      },
      "source": [
        "When running the following cell, you might encounter some errors or blank content. This is because the LLM cannot get the answer at first. Don't worry; if you re-run it several times, you will get the answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72cc0f59-207b-4469-aca7-985258ac0938"
      },
      "outputs": [],
      "source": [
        "# This example specifies a composite filter\n",
        "retriever.invoke(\"What's a highly rated (above 8.5) science fiction film?\")"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "336eed52-9e81-4401-b68a-7e0d85dce12b"
      },
      "source": [
        "### Parent Document Retriever\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9767bbd1-c04d-49ca-8b7f-9b2226ffd533"
      },
      "source": [
        "When splitting documents for retrieval, there are often conflicting desires:\n",
        "\n",
        "1. You may want to have small documents so that their embeddings can most accurately reflect their meaning. If the documents are too long, the embeddings can lose meaning.\n",
        "2. You want to have long enough documents so that the context of each chunk is retained.\n",
        "\n",
        "The `ParentDocumentRetriever` strikes that balance by splitting and storing small chunks of data. During retrieval, it first fetches the small chunks but then looks up the parent IDs for those chunks and returns those larger documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d41a6bd-09ef-4e63-ab36-6c2755ef45d8"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain.storage import InMemoryStore"
      ],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6134bfc3-ba00-499e-8b79-aa8cf458ae97"
      },
      "outputs": [],
      "source": [
        "# Set two splitters. One is with big chunk size (parent) and one is with small chunk size (child)\n",
        "parent_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=20, separator='\\n')\n",
        "child_splitter = CharacterTextSplitter(chunk_size=400, chunk_overlap=20, separator='\\n')"
      ],
      "execution_count": 45
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b07c079-8602-4ec2-856c-d86fd2486114"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma(\n",
        "    collection_name=\"split_parents\", embedding_function=watsonx_embedding()\n",
        ")\n",
        "\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()"
      ],
      "execution_count": 46
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f574020-af61-43f9-95fb-ef112edbd072"
      },
      "outputs": [],
      "source": [
        "retriever = ParentDocumentRetriever(\n",
        "    vectorstore=vectordb,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")"
      ],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d044f92-aa55-48ef-8b55-0af4c2c31b92"
      },
      "outputs": [],
      "source": [
        "retriever.add_documents(chunks_txt)"
      ],
      "execution_count": 48
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a844598-e9e9-494f-8064-49c4f37caaa9"
      },
      "source": [
        "These are the number of large chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dd72a72-47c2-400e-b365-49dc9c86a225",
        "outputId": "260472b3-4ff6-4e1e-a476-f048d261896f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(list(store.yield_keys()))"
      ],
      "execution_count": 49
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a6dc2f2-540a-4e6a-8602-2e4dbbee16ca"
      },
      "source": [
        "Let's make sure the underlying vector store still retrieves the small chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d18fb714-7f70-4d42-9987-abe61f13cffb"
      },
      "outputs": [],
      "source": [
        "sub_docs = vectordb.similarity_search(\"smoking policy\")"
      ],
      "execution_count": 50
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93f0f5a2-8322-4363-a21a-b34abd3f8169",
        "outputId": "0f281979-bf37-46d5-e1ed-54eee8cdc0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoking Restrictions: Smoking inside company buildings, offices, meeting rooms, and other enclosed spaces is strictly prohibited. This includes electronic cigarettes and vaping devices.\n"
          ]
        }
      ],
      "source": [
        "print(sub_docs[0].page_content)"
      ],
      "execution_count": 51
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b037fb0-0591-462d-b6a0-507cbbaa190a"
      },
      "source": [
        "Then, retrieve the relevant large chunk.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67d10d7d-bf4d-4ae1-ac10-79deae850b3d",
        "outputId": "647ca417-25c2-42cc-cd9b-7c1783613057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoking Restrictions: Smoking inside company buildings, offices, meeting rooms, and other enclosed spaces is strictly prohibited. This includes electronic cigarettes and vaping devices.\n"
          ]
        }
      ],
      "source": [
        "retrieved_docs = retriever.invoke(\"smoking policy\")\n",
        "print(retrieved_docs[0].page_content)"
      ],
      "execution_count": 52
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2477ec4-ba5c-4a9c-9d66-82e4b839f999"
      },
      "source": [
        "# Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73f40e90-711d-415d-85a4-58aa146a9dbc"
      },
      "source": [
        "### Exercise 1\n",
        "### Retrieve top 2 results using vector store-backed retriever\n",
        "\n",
        "Can you retrieve the top two results for the company policy document for the query \"smoking policy\" using the Vector Store-Backed Retriever?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa6a7f1f-708a-484d-9b5e-52a169cadb93",
        "outputId": "89ea22b1-509a-4df1-d116-b5b5e7d8cd7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'companypolicies.txt'}, page_content='Smoking Restrictions: Smoking inside company buildings, offices, meeting rooms, and other enclosed spaces is strictly prohibited. This includes electronic cigarettes and vaping devices.'),\n",
              " Document(metadata={'source': 'companypolicies.txt'}, page_content='Designated Smoking Areas: Smoking is only permitted in designated smoking areas, as marked by appropriate signage. These areas have been chosen to minimize exposure to secondhand smoke and to')]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "\n",
        "vectordb = Chroma.from_documents(documents=chunks_txt, embedding=watsonx_embedding())\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
        "query = \"smoking policy\"\n",
        "docs = retriever.invoke(query)\n",
        "docs"
      ],
      "execution_count": 53
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f42e6e84-eae2-46d2-b63d-ca23e8783ee4"
      },
      "source": [
        "<details>\n",
        "    <summary>Click here for Solution</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=chunks_txt, embedding=watsonx_embedding())\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
        "query = \"smoking policy\"\n",
        "docs = retriever.invoke(query)\n",
        "docs\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65fd88c1-9d19-48d0-87d0-0a2c617ceb34"
      },
      "source": [
        "### Exercise 2\n",
        "### Self-Querying Retriever for a query\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "312b9fb5-e32a-41aa-98af-5bb69bb1bcec"
      },
      "source": [
        "Can you use the Self Querying Retriever to invoke a query with a filter?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "9604a85e-74db-476e-9255-262dd0febc7c",
        "outputId": "5ef9f0f0-4092-4814-d68a-fa01f2a12819"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutputParserException",
          "evalue": "Parsing text\njson  \"query\": \"director\",\"filter\":\"\",\"n\":\"\"n\"n\"n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n raised following error:\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mjson_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mjson_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_string\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36m_parse_json\u001b[0;34m(json_str, parser)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# Parse the JSON string into a Python dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# for the original string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mallowed_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"limit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_and_check_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Got invalid JSON object. Error: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpected_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-54-2780206390.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This example specifies a query with filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m retriever.invoke(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"I want to watch a movie directed by Christopher Nolan\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_other_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 result = self._get_relevant_documents(\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/retrievers/self_query/base.py\u001b[0m in \u001b[0;36m_get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrelevant\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         structured_query = self.query_constructor.invoke(\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5429\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5430\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5431\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5432\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5433\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mrun_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"parser\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             )\n\u001b[0;32m--> 204\u001b[0;31m         return self._call_with_config(\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 output = cast(\n\u001b[1;32m   1939\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1941\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    203\u001b[0m             )\n\u001b[1;32m    204\u001b[0m         return self._call_with_config(\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mStructured\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     64\u001b[0m             )\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             raise OutputParserException(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0;34mf\"Parsing text\\n{text}\\n raised following error:\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             )\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Parsing text\njson  \"query\": \"director\",\"filter\":\"\",\"n\":\"\"n\"n\"n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n raised following error:\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
          ]
        }
      ],
      "source": [
        "\n",
        "# You might encouter some errors or blank content when run the following code.\n",
        "# It is becasue LLM cannot get the answer at first. Don't worry, re-run it several times you will get the answer.\n",
        "\n",
        "vectordb = Chroma.from_documents(docs, watsonx_embedding())\n",
        "\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm(),\n",
        "    vectordb,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        ")\n",
        "\n",
        "# This example specifies a query with filter\n",
        "retriever.invoke(\n",
        "    \"I want to watch a movie directed by Christopher Nolan\"\n",
        ")"
      ],
      "execution_count": 54
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a95714d1-0150-4cfb-a91c-afe7382f35e3"
      },
      "source": [
        "<details>\n",
        "    <summary>Click here for a Solution</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "# You might encouter some errors or blank content when run the following code.\n",
        "# It is becasue LLM cannot get the answer at first. Don't worry, re-run it several times you will get the answer.\n",
        "\n",
        "vectordb = Chroma.from_documents(docs, watsonx_embedding())\n",
        "\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm(),\n",
        "    vectordb,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        ")\n",
        "\n",
        "# This example specifies a query with filter\n",
        "retriever.invoke(\n",
        "    \"I want to watch a movie directed by Christopher Nolan\"\n",
        ")\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e6f91c5-6e06-4731-94f9-1f2753b0caf5"
      },
      "source": [
        "## Authors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69b5dd01-9afd-43c6-8c12-48f087bb0fba"
      },
      "source": [
        "[Kang Wang](https://author.skills.network/instructors/kang_wang)\n",
        "\n",
        "Kang Wang is a Data Scientist in IBM. He is also a PhD Candidate in the University of Waterloo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5748145c-e832-4ea6-b12c-75b4b378175e"
      },
      "source": [
        "### Other Contributors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00171dcc-10c7-49d1-ae16-25fae3c1239a"
      },
      "source": [
        "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo)\n",
        "\n",
        "Joseph has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ce0d2b1-4c8d-4ba0-93c2-672de2f88833"
      },
      "source": [
        "```{## Change Log}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb53c409-c260-4239-b6ce-70f6bdc116a1"
      },
      "source": [
        "```{|Date (YYYY-MM-DD)|Version|Changed By|Change Description||-|-|-|-||2024-07-29|0.1|Kang Wang|Create the lab|}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "139ef6df-27c4-4b45-92e1-883461218768"
      },
      "source": [
        "Copyright © IBM Corporation. All rights reserved.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "prev_pub_hash": "7b245d5a13dda3658f448e990d2ee3f7b0c9eae21542e3ecec8dfce1b522ff5b",
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}