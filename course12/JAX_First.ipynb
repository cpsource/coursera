{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpFBYQrJwTMC",
        "outputId": "a79e4113-8393-427f-c09a-c6f1ac6e587b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "/bin/bash: line 1: lspci: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!lspci | grep nvidia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # Memory info\n",
        "    print(f\"Total memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"Allocated memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "    print(f\"Reserved memory: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BuTymIvxOcK",
        "outputId": "c71a8b80-cc91-43cd-db36-c0d1d1a63de3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU count: 1\n",
            "Current GPU: 0\n",
            "GPU name: Tesla T4\n",
            "Total memory: 15.83 GB\n",
            "Allocated memory: 0.00 GB\n",
            "Reserved memory: 0.00 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow first\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoABwQdWy0dd",
        "outputId": "fe2e668e-89c8-452d-fc79-6c0034f02506"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m147.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m153.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# You can check your TPU setup in Colab like this:\n",
        "import jax\n",
        "print(f\"TPU devices: {jax.device_count()}\")\n",
        "print(f\"TPU cores: {jax.local_device_count()}\")\n",
        "\n",
        "# Or with TensorFlow:\n",
        "import tensorflow as tf\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(f'Running on TPU {tpu.master()}')\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    print(f\"Number of TPU cores: {tpu.num_accelerators()}\")\n",
        "except:\n",
        "    print(\"No TPU detected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzcbIgUzyPxn",
        "outputId": "bc0c805c-7d67-4ffb-d8e3-dd1ecedfa243"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU devices: 1\n",
            "TPU cores: 1\n",
            "No TPU detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def print_tpu_status():\n",
        "    print(\"=\" * 50)\n",
        "    print(\"JAX TPU STATUS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    print(f\"JAX version: {jax.__version__}\")\n",
        "    print(f\"Backend: {jax.default_backend()}\")\n",
        "    print(f\"Devices: {len(jax.devices())}\")\n",
        "\n",
        "    for i, device in enumerate(jax.devices()):\n",
        "        print(f\"\\nDevice {i}:\")\n",
        "        print(f\"  Platform: {device.platform}\")\n",
        "        print(f\"  Kind: {device.device_kind}\")\n",
        "        print(f\"  ID: {device.id}\")\n",
        "\n",
        "    # Test computation\n",
        "    print(f\"\\nTesting computation...\")\n",
        "    x = jnp.array([1, 2, 3, 4])\n",
        "    y = jnp.sum(x**2)\n",
        "    print(f\"Test result: {y}\")\n",
        "    print(f\"Computed on: {y.device}\")  # Remove the () - device is a property, not a method\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "print_tpu_status()\n",
        "\n",
        "# More specific TPU details\n",
        "print(\"Additional TPU Info:\")\n",
        "print(f\"Device type: {jax.devices()[0].device_kind}\")\n",
        "print(f\"Platform: {jax.devices()[0].platform}\")\n",
        "\n",
        "# Test TPU performance\n",
        "import time\n",
        "\n",
        "@jax.jit\n",
        "def benchmark_tpu():\n",
        "    x = jnp.ones((1000, 1000))\n",
        "    return jnp.sum(x @ x @ x)  # Matrix multiplications\n",
        "\n",
        "# Warm up\n",
        "_ = benchmark_tpu()\n",
        "\n",
        "# Time the computation\n",
        "start = time.time()\n",
        "result = benchmark_tpu()\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Benchmark result: {result}\")\n",
        "print(f\"Time taken: {end - start:.4f} seconds\")\n",
        "\n",
        "# Check available memory on TPU\n",
        "def get_tpu_memory():\n",
        "    try:\n",
        "        # Create a small array to test memory\n",
        "        test_array = jnp.ones((1000, 1000))\n",
        "\n",
        "        # Get memory stats\n",
        "        backend = jax.lib.xla_bridge.get_backend()\n",
        "        for device in jax.devices():\n",
        "            try:\n",
        "                memory_info = backend.buffer_from_pyval(test_array, device).device_buffer.memory_stats()\n",
        "                print(f\"Device {device}: {memory_info}\")\n",
        "            except:\n",
        "                print(f\"Device {device}: Memory info not available\")\n",
        "    except Exception as e:\n",
        "        print(f\"Memory check failed: {e}\")\n",
        "\n",
        "get_tpu_memory()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkldJmu4z4Qp",
        "outputId": "99e052c7-1396-4d3f-b9f1-407170c0f734"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "JAX TPU STATUS\n",
            "==================================================\n",
            "JAX version: 0.5.2\n",
            "Backend: tpu\n",
            "Devices: 1\n",
            "\n",
            "Device 0:\n",
            "  Platform: tpu\n",
            "  Kind: TPU v5 lite\n",
            "  ID: 0\n",
            "\n",
            "Testing computation...\n",
            "Test result: 30\n",
            "Computed on: TPU_0(process=0,(0,0,0,0))\n",
            "==================================================\n",
            "Additional TPU Info:\n",
            "Device type: TPU v5 lite\n",
            "Platform: tpu\n",
            "Benchmark result: 999999799296.0\n",
            "Time taken: 0.0001 seconds\n",
            "Device TPU_0(process=0,(0,0,0,0)): Memory info not available\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-3646849435.py:61: DeprecationWarning: jax.lib.xla_bridge.get_backend is deprecated; use jax.extend.backend.get_backend.\n",
            "  backend = jax.lib.xla_bridge.get_backend()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def print_tpu_status():\n",
        "    print(\"=\" * 50)\n",
        "    print(\"JAX TPU STATUS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    print(f\"JAX version: {jax.__version__}\")\n",
        "    print(f\"Backend: {jax.default_backend()}\")\n",
        "    print(f\"Devices: {len(jax.devices())}\")\n",
        "\n",
        "    for i, device in enumerate(jax.devices()):\n",
        "        print(f\"\\nDevice {i}:\")\n",
        "        print(f\"  Platform: {device.platform}\")\n",
        "        print(f\"  Kind: {device.device_kind}\")\n",
        "        print(f\"  ID: {device.id}\")\n",
        "\n",
        "    # Test computation\n",
        "    print(f\"\\nTesting computation...\")\n",
        "    x = jnp.array([1, 2, 3, 4])\n",
        "    y = jnp.sum(x**2)\n",
        "    print(f\"Test result: {y}\")\n",
        "    print(f\"Computed on: {y.device}\")  # Fixed: removed ()\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "# Updated memory info function with new API\n",
        "def get_tpu_memory():\n",
        "    try:\n",
        "        # Use the new backend API\n",
        "        backend = jax.extend.backend.get_backend()\n",
        "        print(f\"Backend platform: {backend.platform}\")\n",
        "\n",
        "        # Create a test array\n",
        "        test_array = jnp.ones((1000, 1000))\n",
        "\n",
        "        for i, device in enumerate(jax.devices()):\n",
        "            print(f\"Device {i} ({device.device_kind}): Active\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Backend info error: {e}\")\n",
        "\n",
        "# Comprehensive status\n",
        "print_tpu_status()\n",
        "print(\"\\nBackend Information:\")\n",
        "get_tpu_memory()\n",
        "\n",
        "# TPU performance test\n",
        "print(\"\\nTPU Performance Test:\")\n",
        "import time\n",
        "\n",
        "@jax.jit\n",
        "def tpu_benchmark():\n",
        "    x = jnp.ones((2000, 2000))\n",
        "    return jnp.sum(x @ x)\n",
        "\n",
        "# Warm up JIT compilation\n",
        "_ = tpu_benchmark()\n",
        "\n",
        "# Actual benchmark\n",
        "start = time.time()\n",
        "result = tpu_benchmark()\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Matrix operation result: {result}\")\n",
        "print(f\"Computation time: {end - start:.4f} seconds\")\n",
        "print(f\"Executed on: {result.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8i0B5D018nc",
        "outputId": "21dd8793-9124-40d6-d6b8-5f5e9d647101"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "JAX TPU STATUS\n",
            "==================================================\n",
            "JAX version: 0.5.2\n",
            "Backend: tpu\n",
            "Devices: 1\n",
            "\n",
            "Device 0:\n",
            "  Platform: tpu\n",
            "  Kind: TPU v5 lite\n",
            "  ID: 0\n",
            "\n",
            "Testing computation...\n",
            "Test result: 30\n",
            "Computed on: TPU_0(process=0,(0,0,0,0))\n",
            "==================================================\n",
            "\n",
            "Backend Information:\n",
            "Backend info error: module 'jax' has no attribute 'extend'\n",
            "\n",
            "TPU Performance Test:\n",
            "Matrix operation result: 8000000000.0\n",
            "Computation time: 0.0001 seconds\n",
            "Executed on: TPU_0(process=0,(0,0,0,0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def print_tpu_status():\n",
        "    print(\"=\" * 50)\n",
        "    print(\"JAX TPU STATUS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    print(f\"JAX version: {jax.__version__}\")\n",
        "    print(f\"Backend: {jax.default_backend()}\")\n",
        "    print(f\"Devices: {len(jax.devices())}\")\n",
        "\n",
        "    for i, device in enumerate(jax.devices()):\n",
        "        print(f\"\\nDevice {i}:\")\n",
        "        print(f\"  Platform: {device.platform}\")\n",
        "        print(f\"  Kind: {device.device_kind}\")\n",
        "        print(f\"  ID: {device.id}\")\n",
        "\n",
        "    # Test computation\n",
        "    print(f\"\\nTesting computation...\")\n",
        "    x = jnp.array([1, 2, 3, 4])\n",
        "    y = jnp.sum(x**2)\n",
        "    print(f\"Test result: {y}\")\n",
        "    print(f\"Computed on: {y.device}\")\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "# Simple backend info without deprecated calls\n",
        "def get_backend_info():\n",
        "    print(\"Backend Information:\")\n",
        "    print(f\"Default backend: {jax.default_backend()}\")\n",
        "    print(f\"Available backends: {jax.lib.xla_bridge.get_backend().platform}\")\n",
        "\n",
        "    # Device info\n",
        "    for i, device in enumerate(jax.devices()):\n",
        "        print(f\"Device {i}: {device.device_kind} on {device.platform}\")\n",
        "\n",
        "# Run the status check\n",
        "print_tpu_status()\n",
        "print()\n",
        "get_backend_info()\n",
        "\n",
        "# TPU performance test\n",
        "print(\"\\nTPU Performance Test:\")\n",
        "import time\n",
        "\n",
        "@jax.jit\n",
        "def tpu_benchmark():\n",
        "    x = jnp.ones((2000, 2000))\n",
        "    return jnp.sum(x @ x)\n",
        "\n",
        "# Warm up JIT compilation\n",
        "print(\"Warming up JIT...\")\n",
        "_ = tpu_benchmark()\n",
        "\n",
        "# Actual benchmark\n",
        "print(\"Running benchmark...\")\n",
        "start = time.time()\n",
        "result = tpu_benchmark()\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Matrix operation result: {result}\")\n",
        "print(f\"Computation time: {end - start:.4f} seconds\")\n",
        "print(f\"Executed on: {result.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKJW1cQh2JOW",
        "outputId": "df0c73a1-3cf8-4af1-aaaf-2477db35a104"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "JAX TPU STATUS\n",
            "==================================================\n",
            "JAX version: 0.5.2\n",
            "Backend: tpu\n",
            "Devices: 1\n",
            "\n",
            "Device 0:\n",
            "  Platform: tpu\n",
            "  Kind: TPU v5 lite\n",
            "  ID: 0\n",
            "\n",
            "Testing computation...\n",
            "Test result: 30\n",
            "Computed on: TPU_0(process=0,(0,0,0,0))\n",
            "==================================================\n",
            "\n",
            "Backend Information:\n",
            "Default backend: tpu\n",
            "Available backends: tpu\n",
            "Device 0: TPU v5 lite on tpu\n",
            "\n",
            "TPU Performance Test:\n",
            "Warming up JIT...\n",
            "Running benchmark...\n",
            "Matrix operation result: 8000000000.0\n",
            "Computation time: 0.0003 seconds\n",
            "Executed on: TPU_0(process=0,(0,0,0,0))\n"
          ]
        }
      ]
    }
  ]
}